{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOD91s4xQDhGFe6brQsRfeF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PGriveaud/Meteor4/blob/master/CNN_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5b4ruZ63_Ix",
        "colab_type": "text"
      },
      "source": [
        "https://pytorch.org/tutorials/beginner/examples_nn/two_layer_net_module.html#sphx-glr-beginner-examples-nn-two-layer-net-module-py\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "From the documentation: \\\\\n",
        "https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
        "\n",
        "And more on torch: \\\\\n",
        "https://pytorch.org/docs/stable/torch.html\n",
        "\n",
        "Tutorial on how to implement neural network: \\\\\n",
        "https://medium.com/dair-ai/a-simple-neural-network-from-scratch-with-pytorch-and-google-colab-c7f3830618e0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "619V-d0d1po6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "6a3ad4f4-e190-4be6-b231-190f24b10aa4"
      },
      "source": [
        "import torch\n",
        "\n",
        "class TwoLayerNet(torch.nn.Module):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
        "        member variables.\n",
        "        \"\"\"\n",
        "        super(TwoLayerNet, self).__init__()\n",
        "        self.linear1 = torch.nn.Linear(D_in, H)\n",
        "        self.linear2 = torch.nn.Linear(H, D_out)\n",
        "        self.nonlin = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In the forward function we accept a Tensor of input data and we must return\n",
        "        a Tensor of output data. We can use Modules defined in the constructor as\n",
        "        well as arbitrary operators on Tensors.\n",
        "        \"\"\"\n",
        "        h_relu = self.nonlin(self.linear1(x))\n",
        "        y_pred = self.linear2(h_relu)\n",
        "        return y_pred\n",
        "\n",
        "    \n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random Tensors to hold inputs and outputs\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "# Construct our model by instantiating the class defined above\n",
        "model = TwoLayerNet(D_in, H, D_out)\n",
        "\n",
        "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
        "# in the SGD constructor will contain the learnable parameters of the two\n",
        "# nn.Linear modules which are members of the model.\n",
        "criterion = torch.nn.MSELoss(reduction='sum')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
        "for t in range(500):\n",
        "    # Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = criterion(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 2.569005012512207\n",
            "199 0.03626803681254387\n",
            "299 0.0013703956501558423\n",
            "399 0.0001104991024476476\n",
            "499 1.1799684216384776e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D8A5KwmKN29",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "ff3e8c9e-f9a3-48fd-a2e9-835324e64b78"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class Net2D(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2D, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(n0,n1,kern)           # num channels, size hidden layer, size kernel n0, n1, n2, kern, \n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(n1, n2, kern)\n",
        "\n",
        "        dim_x = math.floor((D_in - (kern - 1))/2)\n",
        "        dim_x = math.floor((dim_x - (kern - 1))/2)\n",
        "        dim_x = dim_x*dim_x*n2\n",
        "        self.dim_x = dim_x\n",
        "\n",
        "        self.fc1 = nn.Linear(dim_x, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, self.dim_x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# N is batch size; C is number of channel\n",
        "# D_in is input dimension; D_out is output dimension.\n",
        "N, C, D_in, D_out = 1, 1, 50, 10\n",
        "\n",
        "# n0 is channel on input; n1 channel out conv1; \n",
        "# n2; channel out conv2; kern is kernel size.\n",
        "n0, n1, n2, kern = 1, 6, 16, 5\n",
        "\n",
        "#Defining input and output:\n",
        "\n",
        "x = torch.randn(N, n0, D_in, D_in)\n",
        "y = torch.randn(N, n0, D_out, D_out)\n",
        "\n",
        "\n",
        "model = Net2D()\n",
        "\n",
        "criterion = torch.nn.MSELoss(reduction='sum')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
        "for t in range(500):\n",
        "    # Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = criterion(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([1, 1, 10, 10])) that is different to the input size (torch.Size([1, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "99 96.34966278076172\n",
            "199 96.2914047241211\n",
            "299 96.2913589477539\n",
            "399 96.29137420654297\n",
            "499 96.29136657714844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq5w2kqAXvke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "6040521f-71c5-4205-b2c3-b7d58b0c1988"
      },
      "source": [
        "D_in = 35\n",
        "kern = 5\n",
        "dim_x = math.floor((D_in - (kern - 1))/2)\n",
        "print(dim_x)\n",
        "dim_x = math.floor((dim_x - (kern - 1))/2)\n",
        "print(dim_x)\n",
        "dim_x = dim_x*dim_x*n2\n",
        "print(dim_x)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n",
            "5\n",
            "400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_3kM5BjUZXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Net1D(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2D, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)           # num channels, size hidden layer, size kernel\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16*5*5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        print('before pooling', np.shape(x))\n",
        "        x = self.pool(x)\n",
        "        print('After pooling', np.shape(x))\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        print('conv1', np.shape(x))\n",
        "        x = self.pool(x)\n",
        "        #print('After pooling', np.shape(x))\n",
        "\n",
        "        #x = self.pool(F.relu(self.conv2(x)))\n",
        "        #print(np.shape(x))\n",
        "\n",
        "        x = x.view(-1, 16*5*5)\n",
        "        #x = torch.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srMTpuoQKLZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sine waves\n",
        "A0 = 1\n",
        "f0 = 1\n",
        "t0 = 1 \n",
        "phi0 = 1\n",
        "\n",
        "y1 = A0*np.sin(2*np.pi*f0*(t - t0) + phi0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Biidx2RFfhde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}