# -*- coding: utf-8 -*-
"""MLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PfFxqS-f57Xi9bp4Y_QETaO2Nk-kXw-o
"""

import numpy as np

class MLP:
  def __init__(self, dim_input, dim_hid, dim_output, num_layers):
    self.dim_input = dim_input
    self.dim_hid = dim_hid
    self.dim_output = dim_output
    self.num_layers = num_layers

    self.weight = []
    self.dimensions = [dim_input] + [dim_hid]*(num_layers-1) + [dim_output]   

    for i in range(self.num_layers):
      w = np.random.rand(self.dimensions[i],self.dimensions[i+1])
      #print(f"weight {i} = {w}")
      self.weight.append(w)

  def nonlinearity(self, x):
    return 1/(1+np.exp(-x))

  def feedforward(self, input):
    self.bias = []
    a_i = []
    a_i.append(input)

    for i in range(self.num_layers):
      b = np.random.rand(self.dimensions[i+1])
      self.bias.append(b)
      h = np.dot(a_i[i], self.weight[i]) + self.bias[i]
      a = self.nonlinearity(h)
      a_i.append(a)
      
      output = a_i[-1]
    return output

if __name__ == "__main__":
  mlp = MLP(5, 10, 1, 4)
  x = [5, 2, 3, 7, 9]
  y = mlp.feedforward(x)

  print(f"output y = {y}")



#print(mlp.bias1)
w0 = mlp.weight[0]
bias = mlp.bias
#print(w0)


output_th = 1/(1 + np.exp(-(bias[0] + w0[0]*x[0] + w0[1]*x[1])))

print(output_th)

